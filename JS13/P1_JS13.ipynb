{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e840ddc",
   "metadata": {},
   "source": [
    "# PRAKTIKUM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa73152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.251752868116324\n",
      "Epoch 1000, Loss: 0.24963278663886684\n",
      "Epoch 2000, Loss: 0.24816953701191866\n",
      "Epoch 3000, Loss: 0.2380828966800584\n",
      "Epoch 4000, Loss: 0.20065101202178134\n",
      "Epoch 5000, Loss: 0.15850727958392472\n",
      "Epoch 6000, Loss: 0.03400699807178907\n",
      "Epoch 7000, Loss: 0.012353421501270476\n",
      "Epoch 8000, Loss: 0.0070857170556668046\n",
      "Epoch 9000, Loss: 0.004866562338379744\n",
      "Prediksi:\n",
      "[[0.06689548]\n",
      " [0.94502273]\n",
      " [0.93951496]\n",
      " [0.05940895]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Parameter\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 1\n",
    "lr = 0.1\n",
    "\n",
    "# Inisialisasi bobot\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Hitung error\n",
    "    error = y - a2\n",
    "\n",
    "    # Backpropagation\n",
    "    d_a2 = error * sigmoid_derivative(a2)\n",
    "    d_W2 = np.dot(a1.T, d_a2)\n",
    "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "\n",
    "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
    "    d_W1 = np.dot(X.T, d_a1)\n",
    "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "    # Update bobot\n",
    "    W1 += lr * d_W1\n",
    "    b1 += lr * d_b1\n",
    "    W2 += lr * d_W2\n",
    "    b2 += lr * d_b2\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(error))\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# Output akhir\n",
    "print(\"Prediksi:\")\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5dabcd",
   "metadata": {},
   "source": [
    "Tugas 1:\n",
    "\n",
    "- Ubah jumlah neuron hidden layer menjadi 3.\n",
    "- Bandingkan hasil loss dengan konfigurasi awal.\n",
    "- Tambahkan fungsi aktivasi ReLU dan bandingkan hasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bb5ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Konfigurasi awal: 2 neuron + sigmoid ===\n",
      "sigmoid hidden_size=2, Epoch 0, Loss: 0.27864\n",
      "sigmoid hidden_size=2, Epoch 1000, Loss: 0.19965\n",
      "sigmoid hidden_size=2, Epoch 2000, Loss: 0.04256\n",
      "sigmoid hidden_size=2, Epoch 3000, Loss: 0.01454\n",
      "sigmoid hidden_size=2, Epoch 4000, Loss: 0.00798\n",
      "sigmoid hidden_size=2, Epoch 5000, Loss: 0.00534\n",
      "sigmoid hidden_size=2, Epoch 6000, Loss: 0.00396\n",
      "sigmoid hidden_size=2, Epoch 7000, Loss: 0.00313\n",
      "sigmoid hidden_size=2, Epoch 8000, Loss: 0.00257\n",
      "sigmoid hidden_size=2, Epoch 9000, Loss: 0.00218\n",
      "\n",
      "=== Konfigurasi baru: 3 neuron + ReLU ===\n",
      "relu hidden_size=3, Epoch 0, Loss: 0.24505\n",
      "relu hidden_size=3, Epoch 1000, Loss: 0.00603\n",
      "relu hidden_size=3, Epoch 2000, Loss: 0.00232\n",
      "relu hidden_size=3, Epoch 3000, Loss: 0.00137\n",
      "relu hidden_size=3, Epoch 4000, Loss: 0.00096\n",
      "relu hidden_size=3, Epoch 5000, Loss: 0.00073\n",
      "relu hidden_size=3, Epoch 6000, Loss: 0.00058\n",
      "relu hidden_size=3, Epoch 7000, Loss: 0.00049\n",
      "relu hidden_size=3, Epoch 8000, Loss: 0.00041\n",
      "relu hidden_size=3, Epoch 9000, Loss: 0.00036\n",
      "\n",
      "Prediksi akhir (sigmoid 2 neuron):\n",
      "[[0.04395898]\n",
      " [0.95907167]\n",
      " [0.95048633]\n",
      " [0.03857172]]\n",
      "Prediksi akhir (ReLU 3 neuron):\n",
      "[[0.01392482]\n",
      " [0.98982113]\n",
      " [0.97107635]\n",
      " [0.01204619]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dataset XOR\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Fungsi aktivasi\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Fungsi untuk training\n",
    "def train_nn(hidden_size, activation='sigmoid', epochs=10000, lr=0.1):\n",
    "    input_size = 2\n",
    "    output_size = 1\n",
    "    \n",
    "    W1 = np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros((1, output_size))\n",
    "    \n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        z1 = np.dot(X, W1) + b1\n",
    "        if activation == 'sigmoid':\n",
    "            a1 = sigmoid(z1)\n",
    "            a1_der = sigmoid_derivative(a1)\n",
    "        else:\n",
    "            a1 = relu(z1)\n",
    "            a1_der = relu_derivative(a1)\n",
    "            \n",
    "        z2 = np.dot(a1, W2) + b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        # Error\n",
    "        error = y - a2\n",
    "        loss = np.mean(np.square(error))\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"{activation} hidden_size={hidden_size}, Epoch {epoch}, Loss: {loss:.5f}\")\n",
    "        loss_history.append(loss)\n",
    "        \n",
    "        # Backpropagation\n",
    "        d_a2 = error * sigmoid_derivative(a2)\n",
    "        d_W2 = np.dot(a1.T, d_a2)\n",
    "        d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
    "        \n",
    "        d_a1 = np.dot(d_a2, W2.T) * a1_der\n",
    "        d_W1 = np.dot(X.T, d_a1)\n",
    "        d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
    "        \n",
    "        # Update bobot\n",
    "        W1 += lr * d_W1\n",
    "        b1 += lr * d_b1\n",
    "        W2 += lr * d_W2\n",
    "        b2 += lr * d_b2\n",
    "    \n",
    "    return loss_history, a2\n",
    "\n",
    "# 1️⃣ Konfigurasi awal: 2 neuron, sigmoid\n",
    "print(\"=== Konfigurasi awal: 2 neuron + sigmoid ===\")\n",
    "loss_sigmoid_2, pred_sigmoid_2 = train_nn(hidden_size=2, activation='sigmoid')\n",
    "\n",
    "# 2️⃣ Konfigurasi baru: 3 neuron, ReLU\n",
    "print(\"\\n=== Konfigurasi baru: 3 neuron + ReLU ===\")\n",
    "loss_relu_3, pred_relu_3 = train_nn(hidden_size=3, activation='relu')\n",
    "\n",
    "# Hasil prediksi akhir\n",
    "print(\"\\nPrediksi akhir (sigmoid 2 neuron):\")\n",
    "print(pred_sigmoid_2)\n",
    "print(\"Prediksi akhir (ReLU 3 neuron):\")\n",
    "print(pred_relu_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
