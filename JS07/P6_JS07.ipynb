{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f7384c4",
   "metadata": {},
   "source": [
    "# **PRAKTIKUM 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfe5e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact NN done in 4.428 s\n",
      "Annoy done in 0.059 s\n",
      "HNSW done in 0.052 s\n",
      "FAISS IVF done in 0.022 s\n",
      "\n",
      "Top-5 neighbors for first song sample:\n",
      "Exact NN: [   0 3836 2788 4042 2519]\n",
      "Annoy:    [0, 3836, 2788, 4042, 2519]\n",
      "HNSW:     [   0 3836 2788 4042 2519]\n",
      "FAISS:    [   0 3836 2788 4042 2519]\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# üîç Perbandingan Exact NN, Annoy, HNSW, FAISS (Optimized)\n",
    "# =============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import faiss\n",
    "from annoy import AnnoyIndex\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -------------------------------\n",
    "# 1Ô∏è‚É£ Load dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv('dataset/songs_with_attributes_and_lyrics.csv')\n",
    "\n",
    "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
    "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "X = df[features].values\n",
    "\n",
    "# Gunakan subset dulu biar cepat (misal 5000 lagu)\n",
    "X = X[:5000]\n",
    "\n",
    "# -------------------------------\n",
    "# 2Ô∏è‚É£ Standarisasi fitur\n",
    "# -------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "k = 10  # jumlah nearest neighbors\n",
    "sample_queries = X_scaled[:100]  # cuma ambil 100 data untuk test query\n",
    "\n",
    "# -------------------------------\n",
    "# 3Ô∏è‚É£ Exact Nearest Neighbor (brute-force)\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "nn.fit(X_scaled)\n",
    "dist_exact, idx_exact = nn.kneighbors(sample_queries)\n",
    "time_exact = time.time() - start\n",
    "print(f\"Exact NN done in {time_exact:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4Ô∏è‚É£ Annoy\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "f = X_scaled.shape[1]\n",
    "index_annoy = AnnoyIndex(f, 'euclidean')\n",
    "for i, v in enumerate(X_scaled):\n",
    "    index_annoy.add_item(i, v)\n",
    "\n",
    "# build tree (10-20 cukup untuk balancing speed vs accuracy)\n",
    "index_annoy.build(10)\n",
    "\n",
    "# query cuma sebagian\n",
    "idx_annoy = [index_annoy.get_nns_by_vector(v, k) for v in sample_queries]\n",
    "time_annoy = time.time() - start\n",
    "print(f\"Annoy done in {time_annoy:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5Ô∏è‚É£ HNSW\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "p_hnsw = hnswlib.Index(space='l2', dim=X_scaled.shape[1])\n",
    "p_hnsw.init_index(max_elements=X_scaled.shape[0], ef_construction=100, M=12)\n",
    "p_hnsw.add_items(X_scaled)\n",
    "p_hnsw.set_ef(100)\n",
    "\n",
    "idx_hnsw, dist_hnsw = p_hnsw.knn_query(sample_queries, k=k)\n",
    "time_hnsw = time.time() - start\n",
    "print(f\"HNSW done in {time_hnsw:.3f} s\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6Ô∏è‚É£ FAISS IVF\n",
    "# -------------------------------\n",
    "start = time.time()\n",
    "quantizer = faiss.IndexFlatL2(X_scaled.shape[1])\n",
    "index_faiss = faiss.IndexIVFFlat(quantizer, X_scaled.shape[1], 50, faiss.METRIC_L2)  # ‚Üê pakai posisi, bukan keyword\n",
    "\n",
    "index_faiss.train(X_scaled)\n",
    "index_faiss.add(X_scaled)\n",
    "index_faiss.nprobe = 5\n",
    "\n",
    "dist_faiss, idx_faiss = index_faiss.search(sample_queries, k)\n",
    "time_faiss = time.time() - start\n",
    "print(f\"FAISS IVF done in {time_faiss:.3f} s\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# 7Ô∏è‚É£ Bandingkan hasil untuk satu lagu\n",
    "# -------------------------------\n",
    "print(\"\\nTop-5 neighbors for first song sample:\")\n",
    "print(f\"Exact NN: {idx_exact[0][:5]}\")\n",
    "print(f\"Annoy:    {idx_annoy[0][:5]}\")\n",
    "print(f\"HNSW:     {idx_hnsw[0][:5]}\")\n",
    "print(f\"FAISS:    {idx_faiss[0][:5]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
